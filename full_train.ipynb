{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db19b5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "\n",
    "def prep_df(parquet_urls):\n",
    "    if isinstance(parquet_urls, str):\n",
    "        parquet_urls = [parquet_urls]\n",
    "\n",
    "    # Read and concatenate all Parquet files\n",
    "    df_list = []\n",
    "    for url in parquet_urls:\n",
    "        df_part = pd.read_parquet(url)\n",
    "        df_part.columns = df_part.columns.str.lower().str.replace(\" \", \"_\")\n",
    "        df_list.append(df_part)\n",
    "\n",
    "    df = pd.concat(df_list, ignore_index=True)\n",
    "    col_to_del = [\n",
    "        \"tpep_pickup_datetime\",\n",
    "        \"tpep_dropoff_datetime\",\n",
    "        \"ratecodeid\",\n",
    "        \"store_and_fwd_flag\",\n",
    "        \"payment_type\",\n",
    "        \"congestion_surcharge\",\n",
    "        \"airport_fee\",\n",
    "        \"pulocationid\",\n",
    "        \"dolocationid\",\n",
    "    ]\n",
    "\n",
    "    df[\"duration\"] = (\n",
    "        df[\"tpep_dropoff_datetime\"] - df[\"tpep_pickup_datetime\"]\n",
    "    ).dt.total_seconds() / 60\n",
    "\n",
    "    dt = df[\"tpep_pickup_datetime\"]\n",
    "    df[\"hour\"] = dt.dt.hour\n",
    "    df[\"dayofweek\"] = dt.dt.dayofweek\n",
    "    df[\"is_weekend\"] = (df[\"dayofweek\"] >= 5).astype(int)\n",
    "\n",
    "    df[\"pu_do\"] = df[\"pulocationid\"].astype(str) + \"_\" + df[\"dolocationid\"].astype(str)\n",
    "\n",
    "    df[\"passenger_count\"] = df[\"passenger_count\"].fillna(\n",
    "        df[\"passenger_count\"].mode()[0]\n",
    "    )\n",
    "\n",
    "    df = df.drop(columns=col_to_del)\n",
    "\n",
    "    df = df[\n",
    "        df[\"duration\"].between(\n",
    "            0.0001,  # Use a small positive value instead of 0 to be safe\n",
    "            df[\"duration\"].quantile(0.99),\n",
    "            inclusive=\"neither\",  # > 0 and < quantile\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    target_col = \"duration\"\n",
    "\n",
    "    X = df.drop(columns=[target_col])\n",
    "    y = df[target_col]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def train_catboost_model(X_train, X_test, y_train, y_test):\n",
    "    cat_cols = [\n",
    "        \"vendorid\",\n",
    "        \"hour\",\n",
    "        \"dayofweek\",\n",
    "        \"is_weekend\",\n",
    "        \"pu_do\",\n",
    "    ]\n",
    "    cat_feature_indices = [X_train.columns.get_loc(col) for col in cat_cols]\n",
    "\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=300,\n",
    "        learning_rate=0.05,\n",
    "        depth=8,\n",
    "        loss_function=\"RMSE\",\n",
    "        random_seed=42,\n",
    "        verbose=100,\n",
    "        task_type=\"GPU\",  # Enable GPU training\n",
    "        devices=\"0\",  # Use the first GPU\n",
    "        border_count=32,  # Optimize for GPU speed\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        cat_features=cat_feature_indices,\n",
    "        eval_set=(X_test, y_test),\n",
    "        use_best_model=True,\n",
    "    )\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    rmse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(\"RMSE:\", rmse)\n",
    "    print(\"MAE:\", mae)\n",
    "    print(\"R²:\", r2)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7af1fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = prep_df(\n",
    "    [\n",
    "        \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet\",\n",
    "        \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet\",\n",
    "        \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-01.parquet\",\n",
    "        \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-01.parquet\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cee01e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 9.0988594\ttest: 9.0896116\tbest: 9.0896116 (0)\ttotal: 1.27s\tremaining: 6m 20s\n",
      "100:\tlearn: 3.0451554\ttest: 3.0350846\tbest: 3.0350846 (100)\ttotal: 2m 14s\tremaining: 4m 24s\n",
      "200:\tlearn: 2.7963353\ttest: 2.7863369\tbest: 2.7863369 (200)\ttotal: 4m 14s\tremaining: 2m 5s\n",
      "299:\tlearn: 2.6971170\ttest: 2.6879826\tbest: 2.6879826 (299)\ttotal: 6m 18s\tremaining: 0us\n",
      "bestTest = 2.687982558\n",
      "bestIteration = 299\n",
      "RMSE: 7.22524955905755\n",
      "MAE: 1.4685485138786747\n",
      "R²: 0.9193544389222764\n"
     ]
    }
   ],
   "source": [
    "model = train_catboost_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3b3f945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import base64\n",
    "import pickle\n",
    "\n",
    "def save_model_to_json(model, filepath='model.json'):\n",
    "    \"\"\"\n",
    "    Save CatBoost model to a JSON file with all necessary components\n",
    "    \"\"\"\n",
    "    # Get model parameters\n",
    "    params = model.get_params()\n",
    "    \n",
    "    # Get categorical feature indices\n",
    "    cat_indices = model.get_cat_feature_indices()\n",
    "    \n",
    "    # Save the model binary data as base64 string\n",
    "    # First save to temporary file, then encode\n",
    "    import tempfile\n",
    "    import os\n",
    "    \n",
    "    with tempfile.NamedTemporaryFile(suffix='.cbm', delete=False) as tmp:\n",
    "        tmp_path = tmp.name\n",
    "    \n",
    "    # Save model to temporary file\n",
    "    model.save_model(tmp_path)\n",
    "    \n",
    "    # Read binary data and encode as base64\n",
    "    with open(tmp_path, 'rb') as f:\n",
    "        model_data = f.read()\n",
    "    \n",
    "    # Encode binary data to base64 string\n",
    "    model_data_b64 = base64.b64encode(model_data).decode('utf-8')\n",
    "    \n",
    "    # Clean up temporary file\n",
    "    os.unlink(tmp_path)\n",
    "    \n",
    "    # Create JSON structure\n",
    "    model_json = {\n",
    "        'model_type': 'CatBoostRegressor',\n",
    "        'model_data_b64': model_data_b64,\n",
    "        'parameters': params,\n",
    "        'categorical_indices': cat_indices,\n",
    "        'feature_names': model.feature_names_ if hasattr(model, 'feature_names_') else None,\n",
    "        'metadata': {\n",
    "            'save_timestamp': pd.Timestamp.now().isoformat(),\n",
    "            'catboost_version': model.__class__.__module__.split('.')[0]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save to JSON file\n",
    "    with open(filepath, 'w') as f:\n",
    "        json.dump(model_json, f, indent=2)\n",
    "    \n",
    "    print(f\"✅ Model saved to {filepath}\")\n",
    "    print(f\"   File size: {len(json.dumps(model_json)) / 1024:.2f} KB\")\n",
    "    \n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8344dff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved to model/trip_duration_model_v1.json\n",
      "   File size: 317646.03 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'model/trip_duration_model_v1.json'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_model_to_json(model, 'model/trip_duration_model_v1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a97ad78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_from_json(filepath='model.json'):\n",
    "    \"\"\"\n",
    "    Load CatBoost model from JSON file\n",
    "    \"\"\"\n",
    "    import base64\n",
    "    import tempfile\n",
    "    import os\n",
    "    \n",
    "    # Read JSON file\n",
    "    with open(filepath, 'r') as f:\n",
    "        model_json = json.load(f)\n",
    "    \n",
    "    # Decode base64 model data\n",
    "    model_data = base64.b64decode(model_json['model_data_b64'])\n",
    "    \n",
    "    # Write to temporary file\n",
    "    with tempfile.NamedTemporaryFile(suffix='.cbm', delete=False, delete_on_close=False) as tmp:\n",
    "        tmp_path = tmp.name\n",
    "        tmp.write(model_data)\n",
    "    \n",
    "    # Load model from temporary file\n",
    "    loaded_model = CatBoostRegressor()\n",
    "    loaded_model.load_model(tmp_path)\n",
    "    \n",
    "    # Clean up temporary file\n",
    "    os.unlink(tmp_path)\n",
    "    \n",
    "    print(f\"✅ Model loaded from {filepath}\")\n",
    "    print(f\"   Model parameters: {list(model_json['parameters'].keys())}\")\n",
    "    \n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e91c3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shadowing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
